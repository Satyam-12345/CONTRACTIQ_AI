{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Necessary Libraries for Artificial Neural **Network**"
      ],
      "metadata": {
        "id": "DwFEtoA8bwsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "TdnOWJRfb4Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset  In this step, we are going to import our dataset. Since our dataset is in csv format, we are going to use the read_csv() method of pandas in order to load the dataset."
      ],
      "metadata": {
        "id": "22X0m2BccE_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "3tIZNPUccJK_",
        "outputId": "abf8601b-7958-4645-b42a-a1f56df53244"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b555845-eadd-48b5-b86d-e3a6c9f1517e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b555845-eadd-48b5-b86d-e3a6c9f1517e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f42ea8fdf38e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Dataset\n",
        "data = pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "metadata": {
        "id": "NHnvT1Flc4hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Matrix of Features (X) The basic principle while creating a machine learning model is to generate X also called as Matrix of Features. This X basically contains all our independent variables. Let’s create the same here.**bold text**"
      ],
      "metadata": {
        "id": "GCoj-fH3dRi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,3:-1].values\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyEeHCkKdiKz",
        "outputId": "54626665-e028-4dbd-c836-5edbeefec2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used iloc method of Pandas data frame which allows us to fetch the desired values from the desired column within the dataset. Here as we can see that we are fetching all the data from the 3rd column till the last minus one column. The reason for that is the first 3 columns i.e RowNumber, CustomerId, and Surname have nothing to do with deciding whether the customer is going to exit or not. Hence in this case we started fetching all the values from the 3rd column onwards. Lastly, since our last column is basically a dependent variable hence we have mentioned -1 in iloc method using which allows us to exclude the last column from being included in our matrix of features X."
      ],
      "metadata": {
        "id": "TnoWrb_idvMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# Generating Dependent Variable Vector(Y)**"
      ],
      "metadata": {
        "id": "-CXRsDTWd9ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the same fashion where we have created our matrix of features(X) for the independent variable, we also have to create a dependent variable vector(Y) which will only contain our dependent variable values."
      ],
      "metadata": {
        "id": "qfAuWx1ReA8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Dependent Variable Vectors\n",
        "Y = data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "qxWA03iCeL8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mDiZ-jOeTKj",
        "outputId": "fa00561b-6c8a-4160-9f7e-f2f25c6cfa9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding Categorical Variable Gender**"
      ],
      "metadata": {
        "id": "xN1hJePYeWt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have defined our X and Y, from this point on we are going to start with one of the highly time-consuming phases in any machine learning problem-solving. This phase is known as feature engineering. To define it in a simple manner, feature engineering is a phase where we either generate new variables from existing ones or modify existing variables so as to use them in our machine learning model."
      ],
      "metadata": {
        "id": "Jg0ovSoLebVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above image depicting the structure of the dataset, we can see that most of the variables are numeric in nature with exception of a few – Gender, Country. Essentially, a machine learning model is a mathematical formula that is only going to accept digits as input. So we try to create an ML model using this dataset which contains a mix of data( numeric + string), our model will simply fail during the creation process itself. Hence we need to convert those string values into their numerical equivalent without losing their significance."
      ],
      "metadata": {
        "id": "1IfamunBe_z8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most efficient ways of doing this is by using a technique called encoding. It is a process that will convert strings or categories directly into their numerical equivalent without losing significance."
      ],
      "metadata": {
        "id": "nt7vROsIgDMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here our gender column has only 2 categories which are male and female, we are going to use LabelEncoding. This type of encoding will simply convert this column into a column having values of 0 and 1. In order to use Label Encoding, we are going to use LabelEncoder class from sklearn library."
      ],
      "metadata": {
        "id": "-6XnTJ5cgEIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical Variable Gender\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE1 = LabelEncoder()\n",
        "X[:,2] = np.array(LE1.fit_transform(X[:,2]))"
      ],
      "metadata": {
        "id": "0WJvwFZYgJgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have applied label encoding on the Gender column of our dataset."
      ],
      "metadata": {
        "id": "dUj0I5U9gPI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding Categorical Variable Country**"
      ],
      "metadata": {
        "id": "CO1CAk-_gbfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s deal with another categorical column named country. This column has a cardinality of 3 meaning that it has 3 distinct categories present i.e France, Germany, Spain."
      ],
      "metadata": {
        "id": "oqAtn50WgfNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have 2 options:-\n",
        "\n",
        "1. We can use Label Encoding here and directly convert those values into 0,1,2 like that\n",
        "\n",
        "2. We can use One Hot Encoding here which will convert those strings into a binary vector stream. For example – Spain will be encoded as 001, France will be 010, etc.\n",
        "\n",
        "The first approach is easy and faster to implement. However, once those values are encoded, those will be converted into 0,1,2. However, there does exist another method of encoding known as one-hot encoding. In one hot encoding, all the string values are converted into binary streams of 0’s and 1’s. One-hot encoding ensures that the machine learning algorithm does not assume that higher numbers are more important."
      ],
      "metadata": {
        "id": "5FzksCX2gj_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding Categorical variable Geography\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct =ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder=\"passthrough\")\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "lneCcMQUg6Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used OneHotEncoder class from sklearn in order to perform one-hot encoding. Now you might have a query here. What is the use of ColumnTransformer? Well, ColumnTransformer is another class in sklearn that will allow us to select a particular column from our dataset on which we can apply one-hot encoding."
      ],
      "metadata": {
        "id": "hvVhLzAhhCXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting Dataset into Training and Testing Dataset**"
      ],
      "metadata": {
        "id": "JWmiaPPChEZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we are going to split our dataset into training and testing datasets. This is one of the bedrocks of the entire machine learning process. The training dataset is the one on which our model is going to train while the testing dataset is the one on which we are going to test the performance of our model."
      ],
      "metadata": {
        "id": "oi5qpAoqhJOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting dataset into training and testing dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)a"
      ],
      "metadata": {
        "id": "oQSue236hO5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used the train_test_split function from the sklearn library. We have split our dataset in a configuration such that 80 percent of data will be there in the training phase and 20 percent of data will be in the testing phase."
      ],
      "metadata": {
        "id": "ZkcyzNnMhUL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, the best part about using the train_test_split function from sklearn is that, while splitting it will also be performing data shuffling in order to create a more generalized dataset."
      ],
      "metadata": {
        "id": "RmbxxSKchWcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing Feature Scaling**"
      ],
      "metadata": {
        "id": "MMC_LAJahn2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The very last step in our feature engineering phase is feature scaling. It is a procedure where all the variables are converted into the same scale. Why you might ask?. Sometimes in our dataset, certain variables have very high values while certain variables have very low values. So there is a chance that during model creation, the variables having extremely high-value dominate variables having extremely low value. Because of this, there is a possibility that those variables with the low value might be neglected by our model, and hence feature scaling is necessary."
      ],
      "metadata": {
        "id": "jwM_AF3GhrcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now how we are going to perform feature scaling? Well, there are many ways of performing feature scaling. The two most efficient techniques in the context are:-\n",
        "\n",
        "1. Standardization\n",
        "\n",
        "2. Normalization\n",
        "\n",
        "Whenever standardization is performed, all values in the dataset will be converted into values ranging between -3 to +3. While in the case of normalization, all values will be converted into a range between -1 to +1.\n",
        "\n",
        "There are few conditions on which technique to use and when. Usually, Normalization is used only when our dataset follows a normal distribution while standardization is a universal technique that can be used for any dataset irrespective of the distribution. Here we are going to use Standardization."
      ],
      "metadata": {
        "id": "2p1Qnf69hv7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "pEijn2z6h0Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initializing Artificial Neural Network**"
      ],
      "metadata": {
        "id": "HT_AjRlVh8kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the very first step while creating ANN. Here we are going to create our ann object by using a certain class of Keras named Sequential."
      ],
      "metadata": {
        "id": "89b4sf8niDEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialising ANN\n",
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "Qj0D0HkIiE0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a part of tensorflow 2.0, Keras is now integrated with tensorflow and is now considered as a sub-library of tensorflow. The Sequential class is a part of the models module of Keras library which is a part of the tensorflow library now."
      ],
      "metadata": {
        "id": "_NhxkQh7iTYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Hidden Layers**"
      ],
      "metadata": {
        "id": "FNSxH1YRiWcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we initialize our ann, we are now going to create layers for the same. Here we are going to create a network that will have 2 hidden layers, 1 input layer, and 1 output layer. So, let’s create our very first hidden layer"
      ],
      "metadata": {
        "id": "Pru89Qs8iZMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Adding First Hidden Layer\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
      ],
      "metadata": {
        "id": "amYnalU-ifw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have created our first hidden layer by using the Dense class which is part of the layers module. This class accepts 2 inputs:-\n",
        "\n",
        "# 1. units:- number of neurons that will be present in the respective layer\n",
        "\n",
        "# 2. activation:- specify which activation function to be used"
      ],
      "metadata": {
        "id": "IfjCKfE9ina-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first input, we can try with any other value as there is no hard rule about the number of neurons that should be present in the layer."
      ],
      "metadata": {
        "id": "DBOisBI5iqql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the second input, we are always going to use “relu”[rectified linear unit] as an activation function for hidden layers. Since we are going to create two hidden layers, this same step we are going to repeat for the creation of the second hidden layer as well."
      ],
      "metadata": {
        "id": "lQiG3b_fi2xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Adding Second Hidden Layer\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
      ],
      "metadata": {
        "id": "dvX5uIWsi7JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Output Layer**"
      ],
      "metadata": {
        "id": "L4Sbt2p0i-9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we are going to create our output layer for ann. The output layer will be responsible for giving output."
      ],
      "metadata": {
        "id": "XDPm-qnvjDDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Adding Output Layer\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "bcN0MVRmjHeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here again, we are going to use the Dense class in order to create the output layer. Two important things to remember here:-\n",
        "\n",
        "**1. In a binary classification problem(like this one)** where we will be having only two classes as output (1 and 0), we will be allocating only one neuron to output this result. For the multiclass classification problem, we have to use more than one neuron in the output layer. For example – if our output contains 4 categories then we need to create 4 different neurons[one for each category].\n",
        "\n",
        "**2. For the binary classification Problems**, the activation function that should always be used is sigmoid. For a multiclass classification problem, the activation function that should be used is softmax."
      ],
      "metadata": {
        "id": "WR2LvofCjMl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here since we are dealing with binary classification hence we are allocating only one neuron in the output layer and the activation function which is used is softmax."
      ],
      "metadata": {
        "id": "nwD7sPDpjZ0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compiling Artificial Neural Network**"
      ],
      "metadata": {
        "id": "t03mX1Z_jfeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling ANN\n",
        "ann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wl-bR0zTjg0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used compile method of our ann object in order to compile our network. Compile method accepts the below inputs:-\n",
        "\n",
        "# 1. optimizer:- **bold text** specifies which optimizer to be used in order to perform stochastic gradient descent. experimented with various optimizers like RMSProp, adam and  found that adam optimizer is a reliable one that can be used with any neural network.\n",
        "\n",
        "# **2. loss:-** specifies which loss function should be used. For binary classification, the value should be binary_crossentropy. For multiclass classification, it should be categorical_crossentropy.\n",
        "\n",
        "# **3. metrics:- which performance metrics to be used in order to compute performance. Here we have used accuracy as a performance metric**."
      ],
      "metadata": {
        "id": "fWUXRgpEjpX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fitting Artificial Neural Network**"
      ],
      "metadata": {
        "id": "3JaBibqXkKPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the last step in our ann creation process. Here we are just going to train our ann on the training dataset."
      ],
      "metadata": {
        "id": "oMCN1gYAkQgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting ANN\n",
        "ann.fit(X_train,Y_train,batch_size=32,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbEr43cpkTUQ",
        "outputId": "cf52b62b-8b24-4873-b721-3dde78ae2b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.7880\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7971\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7999\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8052\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8120\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8171\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8186\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8196\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3791 - accuracy: 0.8199\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3742 - accuracy: 0.8200\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8201\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8207\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8394\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8466\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8504\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8533\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8533\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8547\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8562\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8564\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8561\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8561\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8572\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8568\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8572\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8590\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8580\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8590\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8579\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8583\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8585\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8591\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8590\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8591\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8580\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3443 - accuracy: 0.8596\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8585\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8586\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8583\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8584\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8593\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8597\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8597\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8612\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8609\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8600\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8597\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8602\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8599\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8593\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8597\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8615\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8600\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8602\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8600\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8609\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8602\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8610\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8604\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8597\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8609\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8591\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8610\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8599\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8611\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8612\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8622\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8606\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8611\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8622\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8619\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8614\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8619\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8604\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8612\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8626\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8610\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8619\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8615\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8641\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8624\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8612\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8633\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8611\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8627\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8621\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8615\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8618\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8634\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8622\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8625\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8614\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8629\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8627\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8615\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8629\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8633\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8618\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8634\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d624d2bc310>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have used the fit method in order to train our ann. The fit method is accepting 4 inputs in this case:-\n",
        "\n",
        "1.X_train:- Matrix of features for the training dataset\n",
        "\n",
        "2.Y_train:- Dependent variable vectors for the training dataset\n",
        "\n",
        "3.batch_size: how many observations should be there in the batch. Usually, the value for this parameter is 32 but we can experiment with any other value as well.\n",
        "\n",
        "4. epochs: How many times neural networks will be trained. Here the optimal value that I have found from my experience is 100."
      ],
      "metadata": {
        "id": "bMkSTIztkabO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_9ZnGlZkppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training of Artificial Neural Network**"
      ],
      "metadata": {
        "id": "toHgvXMpkkDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that in each epoch our loss is decreasing and our accuracy is increasing. As we can see here that our final accuracy is 86.59 which is pretty remarkable for a neural network with this simplicity.\n",
        "\n",
        "That’s it :). We have created our artificial neural network from scratch using Python.\n",
        "\n",
        "As an additional bonus, I am attaching the code below that will allow us to perform single-point prediction for any custom values of input."
      ],
      "metadata": {
        "id": "YnJCNfzlknMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting Result for Single Point Observation**"
      ],
      "metadata": {
        "id": "FYVWgmM-kv-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting result for Single Observation\n",
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1,50000]])) > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evm5c6LLk1k8",
        "outputId": "c99d5fa1-1522-49f9-9e61-ee90a5ac1eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step\n",
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here our neural network is trying to predict whether our customer is going to exit or not based on the values of independent variables"
      ],
      "metadata": {
        "id": "93g5eaAKk8so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save neural network model**"
      ],
      "metadata": {
        "id": "R0-nAs3_k_yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving created neural network\n",
        "ann.save(\"ANN.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW2M9S_blEjR",
        "outputId": "4df03e2a-682e-4e43-b214-6345da46f5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the h5 file format? Well, h5 is a specific file format used by neural networks. Using this format we can directly save our neural network as a serialized object. It is similar to the pickle file format implementation that we use for storing traditional machine learning models."
      ],
      "metadata": {
        "id": "LaiDAtRXlPnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "60LRMeSrlT4B"
      }
    }
  ]
}